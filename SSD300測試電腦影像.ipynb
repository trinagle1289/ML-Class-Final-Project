{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56b99747-c08d-4d66-b571-fc8362693d5c",
   "metadata": {},
   "source": [
    "#### 參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea249964-73dd-4574-a301-4da043f59b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name='file_name.pth' # 副檔名通常以.pt或.pth儲存，建議使用.pth\n",
    "import torch\n",
    "device=torch.device('cuda') # 'cuda'/'cpu'，import torch\n",
    "num_classes=6 # 物件類別數+1(背景)\n",
    "batch_size=1 # 必為1\n",
    "variances=[0.1,0.2] # 設定gHat中cx、cy與w、h間的權重(須與訓練的設定值相同)\n",
    "top_k=200 # 各類別依scores挑出最大前top_k個後代入NMS，參考值=200\n",
    "NMS_threshold=0.5 # 將同類別且IoU小於等於NMS_threshold的物件視為不同物件。此值愈小邊界框會愈少，參考值=0.5\n",
    "TestImage=r'./resources/validation_image/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6ea438-5481-430f-bc94-7cb4b15c0127",
   "metadata": {},
   "source": [
    "#### 取得網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4d6f189-de30-44dc-8c82-c35645baa790",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class SSD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SSD,self).__init__()\n",
    "\n",
    "        # block_1：Conv1_1~Conv4_3+ReLU\n",
    "        self.block_1=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3,out_channels=64,kernel_size=3,stride=1,padding=1), # [batch_size,64,300,300]\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3,stride=1,padding=1), # [batch_size,64,300,300]\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2), # [batch_size,64,150,150]\n",
    "            nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,stride=1,padding=1), # [batch_size,128,150,150]\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=128,out_channels=128,kernel_size=3,stride=1,padding=1), # [batch_size,128,150,150]\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2), # [batch_size,128,75,75]\n",
    "            nn.Conv2d(in_channels=128,out_channels=256,kernel_size=3,stride=1,padding=1), # [batch_size,256,75,75]\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3,stride=1,padding=1), # [batch_size,256,75,75]\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3,stride=1,padding=1), # [batch_size,256,75,75]\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2,ceil_mode=True), # [batch_size,256,38,38]\n",
    "            nn.Conv2d(in_channels=256,out_channels=512,kernel_size=3,stride=1,padding=1), # [batch_size,512,38,38]\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=512,out_channels=512,kernel_size=3,stride=1,padding=1), # [batch_size,512,38,38] \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=512,out_channels=512,kernel_size=3,stride=1,padding=1), # [batch_size,512,38,38]\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        # Layer learns to scale the L2 normalized features from conv4_3\n",
    "        self.l2norm=L2Norm(512,20) # 512為輸入的特徵圖個數，20為scale\n",
    "         \n",
    "        # block_2：Pool4~Conv7+ReLU\n",
    "        self.block_2=nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2), # [batch_size,512,19,19]\n",
    "            nn.Conv2d(in_channels=512,out_channels=512,kernel_size=3,stride=1,padding=1), # [batch_size,512,19,19]\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=512,out_channels=512,kernel_size=3,stride=1,padding=1), # [batch_size,512,19,19]\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=512,out_channels=512,kernel_size=3,stride=1,padding=1), # [batch_size,512,19,19]\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3,stride=1,padding=1), # [batch_size,512,19,19]\n",
    "            nn.Conv2d(in_channels=512,out_channels=1024,kernel_size=3,stride=1,padding=6,dilation=6), # [batch_size,1024,19,19]\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=1024,out_channels=1024,kernel_size=1,stride=1), # [batch_size,1024,19,19]\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        # block_3：Conv8_1~Conv8_2+ReLU\n",
    "        self.block_3=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1024,out_channels=256,kernel_size=1), # [batch_size,256,19,19]\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256,out_channels=512,kernel_size=3,stride=2,padding=1), # [batch_size,512,10,10]\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        # block_4：Conv9_1~Conv9_2+ReLU\n",
    "        self.block_4=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512,out_channels=128,kernel_size=1), # [batch_size,128,10,10]\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=128,out_channels=256,kernel_size=3,stride=2,padding=1), # [batch_size,256,5,5]\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        # block_5：Conv10_1~Conv10_2+ReLU\n",
    "        self.block_5=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256,out_channels=128,kernel_size=1), # [batch_size,128,5,5]\n",
    "            nn.ReLU(inplace=True),                            \n",
    "            nn.Conv2d(in_channels=128,out_channels=256,kernel_size=3), # [batch_size,256,3,3]\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        # block_6：Conv11_1~Conv11_2+ReLU\n",
    "        self.block_6=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256,out_channels=128,kernel_size=1), # [batch_size,128,3,3]                            \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=128,out_channels=256,kernel_size=3), # [batch_size,256,1,1]\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        # loc_1\n",
    "        self.loc_1=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512,out_channels=4*4,kernel_size=3,stride=1,padding=1), # [batch_size,16,38,38]\n",
    "        )\n",
    "        # conf_1\n",
    "        self.conf_1=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512,out_channels=4*num_classes,kernel_size=3,stride=1,padding=1), # [batch_size,(4*num_classes),38,38]\n",
    "        )\n",
    "        # loc_2\n",
    "        self.loc_2=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1024,out_channels=6*4,kernel_size=3,stride=1,padding=1), # [batch_size,24,19,19]\n",
    "        )\n",
    "        # conf_2\n",
    "        self.conf_2=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1024,out_channels=6*num_classes,kernel_size=3,stride=1,padding=1), # [batch_size,(6*num_classes),19,19]\n",
    "        ) \n",
    "        # loc_3\n",
    "        self.loc_3=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512,out_channels=6*4,kernel_size=3,stride=1,padding=1), # [batch_size,24,10,10]\n",
    "        )\n",
    "        # conf_3\n",
    "        self.conf_3=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512,out_channels=6*num_classes,kernel_size=3,stride=1,padding=1), # [batch_size,(6*num_classes),10,10]\n",
    "        ) \n",
    "        # loc_4\n",
    "        self.loc_4=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256,out_channels=6*4,kernel_size=3,stride=1,padding=1), # [batch_size,24,5,5]\n",
    "        )\n",
    "        # conf_4\n",
    "        self.conf_4=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256,out_channels=6*num_classes,kernel_size=3,stride=1,padding=1), # [batch_size,(6*num_classes),5,5]\n",
    "        )       \n",
    "        # loc_5\n",
    "        self.loc_5=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256,out_channels=4*4,kernel_size=3,stride=1,padding=1), # [batch_size,16,3,3]\n",
    "        )\n",
    "        # conf_5\n",
    "        self.conf_5=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256,out_channels=4*num_classes,kernel_size=3,stride=1,padding=1), # [batch_size,(4*num_classes),3,3]\n",
    "        )   \n",
    "        # loc_6\n",
    "        self.loc_6=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256,out_channels=4*4,kernel_size=3,stride=1,padding=1), # [batch_size,16,1,1]\n",
    "        )\n",
    "        # conf_6\n",
    "        self.conf_6=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256,out_channels=4*num_classes,kernel_size=3,stride=1,padding=1), # [batch_size,(4*num_classes),1,1]\n",
    "        )   \n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.block_1(x) # [batch_size,512,38,38] (Conv4_3+ReLU輸出)\n",
    "        n=self.l2norm(x)\n",
    "        loc1=self.loc_1(n).permute(0,2,3,1).contiguous().view(batch_size,-1).view(batch_size,-1,4)\n",
    "        conf1=self.conf_1(n).permute(0,2,3,1).contiguous().view(batch_size,-1).view(batch_size,-1,num_classes)\n",
    "        x=self.block_2(x) # [batch_size,1024,19,19] (Conv7+ReLU輸出)\n",
    "        loc2=self.loc_2(x).permute(0,2,3,1).contiguous().view(batch_size,-1).view(batch_size,-1,4)\n",
    "        conf2=self.conf_2(x).permute(0,2,3,1).contiguous().view(batch_size,-1).view(batch_size,-1,num_classes)\n",
    "        x=self.block_3(x) # [batch_size,512,10,10] (Conv8_2+ReLU輸出)\n",
    "        loc3=self.loc_3(x).permute(0,2,3,1).contiguous().view(batch_size,-1).view(batch_size,-1,4)\n",
    "        conf3=self.conf_3(x).permute(0,2,3,1).contiguous().view(batch_size,-1).view(batch_size,-1,num_classes)\n",
    "        x=self.block_4(x) # [batch_size,256,5,5] (Conv9_2+ReLU輸出)\n",
    "        loc4=self.loc_4(x).permute(0,2,3,1).contiguous().view(batch_size,-1).view(batch_size,-1,4)\n",
    "        conf4=self.conf_4(x).permute(0,2,3,1).contiguous().view(batch_size,-1).view(batch_size,-1,num_classes)\n",
    "        x=self.block_5(x) # [batch_size,256,3,3] (Conv10_2+ReLU輸出)\n",
    "        loc5=self.loc_5(x).permute(0,2,3,1).contiguous().view(batch_size,-1).view(batch_size,-1,4)\n",
    "        conf5=self.conf_5(x).permute(0,2,3,1).contiguous().view(batch_size,-1).view(batch_size,-1,num_classes)\n",
    "        x=self.block_6(x) # [batch_size,256,1,1] (Conv11_2+ReLU輸出)\n",
    "        loc6=self.loc_6(x).permute(0,2,3,1).contiguous().view(batch_size,-1).view(batch_size,-1,4)\n",
    "        conf6=self.conf_6(x).permute(0,2,3,1).contiguous().view(batch_size,-1).view(batch_size,-1,num_classes)\n",
    "        loc=torch.cat((loc1,loc2,loc3,loc4,loc5,loc6),1) # [batch_size,8732,4]，import torch\n",
    "        conf=torch.cat((conf1,conf2,conf3,conf4,conf5,conf6),1) # [batch_size,8732,num_classes]，import torch\n",
    "        return loc,conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aa0b3f8-d2b9-4906-8489-9e335d160c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class L2Norm(nn.Module):\n",
    "    def __init__(self,in_channels,scale):\n",
    "        super(L2Norm,self).__init__()\n",
    "        self.in_channels=in_channels\n",
    "        self.gamma=scale or None\n",
    "        self.eps=1e-10\n",
    "        self.weight=nn.Parameter(torch.Tensor(self.in_channels)) # from torch import nn，import torch\n",
    "        self.reset_parameters()\n",
    "    def reset_parameters(self):\n",
    "        nn.init.constant_(self.weight,self.gamma) # from torch import nn \n",
    "    def forward(self,x):\n",
    "        norm=x.pow(2).sum(dim=1,keepdim=True).sqrt()+self.eps\n",
    "        x=torch.div(x,norm) # import torch\n",
    "        out=self.weight.unsqueeze(0).unsqueeze(2).unsqueeze(3).expand_as(x)*x\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca9c48c-43a1-40a2-94fe-ef2782fca944",
   "metadata": {},
   "source": [
    "#### 加載模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e372779-e8a6-4d49-8fe3-9e58176a2eab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SSD(\n",
       "  (block_1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "  )\n",
       "  (l2norm): L2Norm()\n",
       "  (block_2): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "  )\n",
       "  (block_3): Sequential(\n",
       "    (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (block_4): Sequential(\n",
       "    (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (block_5): Sequential(\n",
       "    (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (block_6): Sequential(\n",
       "    (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (loc_1): Sequential(\n",
       "    (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (conf_1): Sequential(\n",
       "    (0): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (loc_2): Sequential(\n",
       "    (0): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (conf_2): Sequential(\n",
       "    (0): Conv2d(1024, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (loc_3): Sequential(\n",
       "    (0): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (conf_3): Sequential(\n",
       "    (0): Conv2d(512, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (loc_4): Sequential(\n",
       "    (0): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (conf_4): Sequential(\n",
       "    (0): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (loc_5): Sequential(\n",
       "    (0): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (conf_5): Sequential(\n",
       "    (0): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (loc_6): Sequential(\n",
       "    (0): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (conf_6): Sequential(\n",
       "    (0): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector=SSD().to(device)\n",
    "detector.load_state_dict(torch.load(file_name)) # import torch\n",
    "detector.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b6b946-0309-4273-a627-8a5950847a0d",
   "metadata": {},
   "source": [
    "#### 建立錨框"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2d21976-d91e-4614-b614-848be01a5e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_scale=[38,19,10,5,3,1] # 預測用的特徵圖尺寸(以像素為單位)\n",
    "sk=[0.07,0.15,0.33,0.51,0.69,0.87,1.05] # 各預測特徵圖的默認框尺度(相對於輸入影像的比例)，比預測特徵圖的個數多1\n",
    "aspect_ratio=[[1,2,1/2],[1,2,3,1/2,1/3],[1,2,3,1/2,1/3],[1,2,3,1/2,1/3],[1,2,1/2],[1,2,1/2]] # 各預測特徵圖的縱橫比(須檢查loc、conf的濾波器個數)\n",
    "abox=[]\n",
    "import itertools\n",
    "import math\n",
    "for i,j in enumerate(feature_scale):\n",
    "    for m,n in itertools.product(range(j),repeat=2):\n",
    "        cx=(n+0.5)/j # 等同於cx相對於輸入影像的比例位置(乘以輸入影像尺寸即為cx在輸入影像的像素位置)\n",
    "        cy=(m+0.5)/j # 等同於cy相對於輸入影像的比例位置(乘以輸入影像尺寸即為cy在輸入影像的像素位置)\n",
    "        for ar in aspect_ratio[i]:\n",
    "            abox+=[cx-sk[i]*math.sqrt(ar)/2,cy-sk[i]/math.sqrt(ar)/2,cx+sk[i]*math.sqrt(ar)/2,cy+sk[i]/math.sqrt(ar)/2] # [cxmin cymin cxmax cymax]\n",
    "        abox+=[cx-math.sqrt(sk[i]*sk[i+1])/2,cy-math.sqrt(sk[i]*sk[i+1])/2,cx+math.sqrt(sk[i]*sk[i+1])/2,cy+math.sqrt(sk[i]*sk[i+1])/2] # [xmin ymin xmax ymax]\n",
    "anchor=torch.Tensor(abox).view(-1,4).to(device) # [8732,4] (所有錨框的[xmin ymin xmax ymax]，皆相對於輸入影像的比例位置，乘以輸入影像尺寸即為在輸入影像的像素位置)，import torch\n",
    "anchor.clamp_(max=1, min=0) # 限定最大值為1、最小值0\n",
    "anchor=anchor*300 # 轉換成輸入影像尺寸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5833662f-4867-428d-85f5-54b00e508264",
   "metadata": {},
   "source": [
    "#### 取得影像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "322078c8-cc66-4a14-b8ba-52ce6f1c7fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "transforms=transforms.Compose([transforms.Resize((300,300)),transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]) # ToTensor將影像像素歸一化至0~1(直接除以255)，from torchvision import transforms\n",
    "import cv2 # 匯入cv2套件\n",
    "import os\n",
    "all_image_name=os.listdir(TestImage) # 所有影像檔名(含.jpg)，import os\n",
    "from PIL import Image\n",
    "for image_name in all_image_name:\n",
    "    img_cv=cv2.imread(TestImage+image_name) # 讀取影像(僅用於繪圖)，img：[480,640,3]\n",
    "    I=Image.open(TestImage+image_name,mode='r') # from PIL import Image\n",
    "    img=transforms(I)\n",
    "    img=img.unsqueeze(0) # [1,3,300,300]\n",
    "    img=img.to(device)\n",
    "\n",
    "    # 預測結果\n",
    "    pred_loc,pred_conf=detector(img) # pred_loc：[batch_size,8732,4]，pred_conf：[batch_size,8732,num_classes]\n",
    "    pred_conf=pred_conf.view(batch_size,pred_conf.shape[1],num_classes).transpose(2,1) # [batch_size,num_classes,8732]\n",
    "    max_pred_conf,_=torch.max(pred_conf,dim=1) # 每個錨框最大預測置信值，[batch_size,8732]，import torch\n",
    "    for i in range(batch_size):\n",
    "        pred_cx=(anchor[:,0]+anchor[:,2])/2+pred_loc[i][:,0]*((anchor[:,2]-anchor[:,0])*variances[0]) # 預測的cx，[8732]\n",
    "        pred_cy=(anchor[:,1]+anchor[:,3])/2+pred_loc[i][:,1]*((anchor[:,3]-anchor[:,1])*variances[0]) # 預測的cy，[8732]\n",
    "        pred_w=torch.exp(pred_loc[i][:,2]*variances[1])*(anchor[:,2]-anchor[:,0])  # 預測的w，[8732]，import torch\n",
    "        pred_h=torch.exp(pred_loc[i][:,3]*variances[1])*(anchor[:,3]-anchor[:,1])  # 預測的h，[8732]，import torch\n",
    "        pred_bbox=torch.stack((pred_cx-pred_w/2,pred_cy-pred_h/2,pred_cx+pred_w/2,pred_cy+pred_h/2),dim=1) # 預測的邊界框，[8732,4]，[xmin ymin xmax ymax]，import torch\n",
    "        for j in range(1,num_classes): # 1~(num_classes-1)\n",
    "            c_mask=torch.ge(pred_conf[i][j],max_pred_conf[i]) # 每個錨框對第j(1~(num_classes-1))個類別的預測置信值是否在所有類別(包含背景)中為最大，True/False，[8732]，import torch\n",
    "            scores=pred_conf[i][j][c_mask] # 針對第i個batch的第j個類別，若其預測置信值在所有類別(包含背景)中為最大，則取出其預測置信值，並命其為scores，[如533]\n",
    "            if scores.size(0)==0:\n",
    "                continue\n",
    "            l_mask=c_mask.unsqueeze(1).expand_as(pred_bbox)\n",
    "            boxes=pred_bbox[l_mask].view(-1,4) # 針對第i個batch的第j個物件，找出scores(即大於conf_threshold的置信值)對應的預測邊界框，[如533,4]\n",
    "            area=torch.mul(boxes[:,2]-boxes[:,0],boxes[:,3]-boxes[:,1]) # import torch，針對第i個batch的第j個物件，計算出scores(即大於conf_threshold的置信值)所對應的預測邊界框的面積，[如533]\n",
    "\n",
    "            # NMS\n",
    "            _,idx=scores.sort(0) # idx：scores由小而大排列並取得位置編號，[如533]\n",
    "            idx=idx[-top_k:] # 挑出scores最大前top_k個的位置編號，[top_k]\n",
    "            best_idx=[] # 儲存某類別(不含背景)經NMS後的位置編號\n",
    "            while idx.numel()>0:\n",
    "                b=idx[-1] # 目前scores中最大值的位置編號\n",
    "                cv2.rectangle(img_cv,(int(boxes[b,0]/300*img_cv.shape[1]),int(boxes[b,1]/300*img_cv.shape[0])),(int(boxes[b,2]/300*img_cv.shape[1]),int(boxes[b,3]/300*img_cv.shape[0])),(255,0,0),3)\n",
    "\n",
    "                text = ''\n",
    "                if j == 1:\n",
    "                    text = 'forward | raise two hands'\n",
    "                elif j == 2:\n",
    "                    text = 'stop | stand at attention'\n",
    "                elif j == 3:\n",
    "                    text = 'left'\n",
    "                elif j == 4:\n",
    "                    text = 'right'\n",
    "                elif j == 5:\n",
    "                    text = 'back | hands up'\n",
    "                \n",
    "                cv2.putText(img_cv,f'{text}',(int(boxes[b,0]/300*img_cv.shape[1]),int(boxes[b,1]/300*img_cv.shape[0]+120)),cv2.FONT_HERSHEY_SIMPLEX,5,(255,0,0),10,cv2.LINE_AA)\n",
    "                # cv2.putText(img_cv,f'{j}',(int(boxes[b,0]/300*img_cv.shape[1]),int(boxes[b,1]/300*img_cv.shape[0]+120)),cv2.FONT_HERSHEY_SIMPLEX,5,(255,0,0),10,cv2.LINE_AA)\n",
    "                best_idx.append(b.item())\n",
    "                if idx.size(0)==1:\n",
    "                    break\n",
    "                idx=idx[:-1] # 移除idx中最後一個位置編號(即目前scores中值最大的位置編號)，idx內的位置編號數減少1個\n",
    "                min_x=torch.clamp(torch.index_select(boxes[:,0],0,idx),min=boxes[b,0].item()) # 交集部分的最小x，[top_k]、[top_k-1]、...[1]，import torch\n",
    "                min_y=torch.clamp(torch.index_select(boxes[:,1],0,idx),min=boxes[b,1].item()) # 交集部分的最小y，[top_k]、[top_k-1]、...[1]，import torch\n",
    "                max_x=torch.clamp(torch.index_select(boxes[:,2],0,idx),max=boxes[b,2].item()) # 交集部分的最大x，[top_k]、[top_k-1]、...[1]，import torch\n",
    "                max_y=torch.clamp(torch.index_select(boxes[:,3],0,idx),max=boxes[b,3].item()) # 交集部分的最大y，[top_k]、[top_k-1]、...[1]，import torch\n",
    "                area_inter=torch.clamp(max_x-min_x,min=0.0)*torch.clamp(max_y-min_y,min=0.0) # import torch\n",
    "                IoU=area_inter/(torch.index_select(area,0,idx)+area[b]-area_inter) # scores中最大值的邊界框與剩餘邊界框的IoU，import torch\n",
    "                idx=idx[IoU.le(NMS_threshold)] # 在剩餘邊界框中保留IoU小於等於NMS_threshold的邊界框\n",
    "\n",
    "    img_small=cv2.resize(img_cv,(816,616)) # 改變尺寸\n",
    "    cv2.imshow('Frame',img_small) # 顯示新圖\n",
    "    k=cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-final-report",
   "language": "python",
   "name": "ml-final-report"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
